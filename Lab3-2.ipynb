{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87fee377",
   "metadata": {},
   "source": [
    "# Lab 3 - Part 2: PCA and Clustering (12 marks)\n",
    "### Due Date: Monday, March 13 at 12pm\n",
    "\n",
    "Author: Sam Rainbow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f05d0",
   "metadata": {},
   "source": [
    "The purpose of this portion of the assignment is to practice using PCA and clustering techniques on a given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4299ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a83b6f",
   "metadata": {},
   "source": [
    "## 0. Function definitions (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d602f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def cluster_fn(n_clusters, X, n_components=0):\n",
    "    '''Calculate silhouette score for a given dataset, number of clusters, \n",
    "       and number of principle components using Kmeans clustering (random_state=0)\n",
    "        \n",
    "        n_clusters (int): number of clusters to use for Kmeans\n",
    "        n_components (int): number of principle components (optional)\n",
    "        X (numpy.array or pandas.DataFrame): unlabelled dataset\n",
    "        \n",
    "        returns: silhouette score\n",
    "    \n",
    "    '''\n",
    "    # TODO: Implement function body\n",
    "    if n_components > 0:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X = pca.fit_transform(X)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters).fit(X)\n",
    "    score = silhouette_score(X, kmeans.labels_)\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7cfa4f",
   "metadata": {},
   "source": [
    "## 1. Load data (2 marks)\n",
    "\n",
    "For this assignment, we will use the dataset found below:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Chemical+Composition+of+Ceramic+Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "474481f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import dataset\n",
    "df = pd.read_csv('Chemical Composion of Ceramic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908b657",
   "metadata": {},
   "source": [
    "Two of the columns are non-numeric. For this assignment, we will remove those two columns and focus on clustering the ceramic samples based on the numerical measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2efda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove non-numeric columns\n",
    "df = df.drop(['Ceramic Name', 'Part'], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf578b1",
   "metadata": {},
   "source": [
    "## 2. Implement clustering (8 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c62e1",
   "metadata": {},
   "source": [
    "### 2.1 Cluster using raw data (1 mark)\n",
    "\n",
    "Implement Kmeans clustering using the raw data. Compare the silhouette scores using 2, 3, 4, 5 and 6 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f85da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement clustering with raw data using cluster_fn above\n",
    "raw_data = []\n",
    "\n",
    "for n_clusters in range(2, 7):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(df)\n",
    "    score = silhouette_score(df, kmeans.labels_)\n",
    "    raw_data.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df428e",
   "metadata": {},
   "source": [
    "### 2.2 Cluster using PCA-transformed data (2 marks)\n",
    "\n",
    "Implement Kmeans clustering using the PCA-transformed data. Compare the silhouette scores using 2, 3, 4, 5 and 6 clusters and 2, 3, 4, 5 and 6 principle components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de0a5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement clustering with PCA-transformed data using cluster_fn above\n",
    "pca_data = []\n",
    "for n_clusters in range(2, 7):\n",
    "    for n_components in range(2, 7):\n",
    "        score = cluster_fn(n_clusters=n_clusters, X=df, n_components=n_components)\n",
    "        pca_data.append(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb5219",
   "metadata": {},
   "source": [
    "### 2.3 Display results (2 marks)\n",
    "\n",
    "Print the results for 2.1 and 2.2 in a table. Include column and row labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ae81ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             2 Clusters  3 Clusters  4 Clusters  5 Clusters  6 Clusters\n",
      "PCA - 2 PCs    0.619442    0.599961    0.589955    0.587472    0.585963\n",
      "PCA - 3 PCs    0.611625    0.586609    0.570949    0.567470    0.564725\n",
      "PCA - 4 PCs    0.600752    0.570531    0.553715    0.549286    0.546752\n",
      "PCA - 5 PCs    0.567088    0.542209    0.521348    0.519533    0.512537\n",
      "PCA - 6 PCs    0.569320    0.546232    0.529829    0.524216    0.521257\n",
      "Raw Data       0.584013    0.561640    0.543411    0.508064    0.510399\n"
     ]
    }
   ],
   "source": [
    "# TODO: Display results\n",
    "rows = ['PCA - 2 PCs', 'PCA - 3 PCs', 'PCA - 4 PCs', 'PCA - 5 PCs', 'PCA - 6 PCs', 'Raw Data']\n",
    "columns = ['2 Clusters', '3 Clusters', '4 Clusters', '5 Clusters', '6 Clusters']\n",
    "data = np.array(pca_data + raw_data).reshape(6, 5)\n",
    "\n",
    "table = pd.DataFrame(data, index=rows, columns=columns)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1086de9",
   "metadata": {},
   "source": [
    "**Question**: Which combination of number of clusters and number of components produced the best results? What is the silhouette score for this combination? **(3 marks)**\n",
    "\n",
    "The best results were produced by the combination of 2 clusters and 2 principal components with a silhouette score of 0.619"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e64bf4a",
   "metadata": {},
   "source": [
    "## 3. Improve results (Bonus - 3 marks)\n",
    "\n",
    "Think about how you could improve the results from the previous section. Two potential methods include preprocessing the data or selecting a different clustering algorithm. Repeat section 2 with your selected improvement method to determine what the new silhouette scores would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a8a9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Scaled Data Silhouette Scores----------------------\n",
      "             2 Clusters  3 Clusters  4 Clusters  5 Clusters  6 Clusters\n",
      "PCA - 2 PCs    0.548234    0.460124    0.406468    0.375081    0.350386\n",
      "PCA - 3 PCs    0.609737    0.477870    0.419754    0.369801    0.339810\n",
      "PCA - 4 PCs    0.591239    0.436154    0.392035    0.329281    0.310642\n",
      "PCA - 5 PCs    0.510540    0.422588    0.370892    0.319624    0.296287\n",
      "PCA - 6 PCs    0.512535    0.425467    0.363046    0.318278    0.299232\n",
      "Raw Data       0.286008    0.268343    0.242909    0.231110    0.221541\n"
     ]
    }
   ],
   "source": [
    "# TODO: Repeat steps 2.1-2.3 using a different method/preprocessing/etc.\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "raw_data = []\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df)\n",
    "\n",
    "for n_clusters in range(2, 7):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(X_scaled)\n",
    "    score = silhouette_score(X_scaled, kmeans.labels_)\n",
    "    raw_data.append(score)\n",
    "\n",
    "pca_data = []\n",
    "for n_clusters in range(2, 7):\n",
    "    for n_components in range(2, 7):\n",
    "        score = cluster_fn(n_clusters=n_clusters, X=X_scaled, n_components=n_components)\n",
    "        pca_data.append(score)\n",
    "\n",
    "print(\"-----------------Scaled Data Silhouette Scores----------------------\")\n",
    "rows = ['PCA - 2 PCs', 'PCA - 3 PCs', 'PCA - 4 PCs', 'PCA - 5 PCs', 'PCA - 6 PCs', 'Raw Data']\n",
    "columns = ['2 Clusters', '3 Clusters', '4 Clusters', '5 Clusters', '6 Clusters']\n",
    "data = np.array(pca_data + raw_data).reshape(6, 5)\n",
    "\n",
    "table = pd.DataFrame(data, index=rows, columns=columns)\n",
    "\n",
    "print(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4193d4",
   "metadata": {},
   "source": [
    "**Question**: Why did you select this improvement method? Which combination of number of clusters and number of components produced the best results? Did you improve the silhouette scores? If yes, how much of an improvement did you get over the previous results?\n",
    "\n",
    "I attempted to scale the data using the MinMaxScaler() as well as the StandardScaler() but neither improved the model. The highest result was 0.615 with the MinMaxScaler with 2 clusters and 2 principal components and 0.6097 with the StandardScaler with 2 clusters and 3 principle components. I selected this improvment method in an attempt to reduce the influence of features with large values that might create biased results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
